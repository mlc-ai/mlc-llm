





<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8">
  <meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>How to Compile Models &mdash; mlc-llm 0.1.0 documentation</title>
  

  
  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0/css/bootstrap.min.css" integrity="sha384-Gn5384xqQ1aoWXA+058RXPxPg6fy4IWvTNh0E263XmFcJlSAwiGgFAW/dAiS6JXm" crossorigin="anonymous">
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/tabs.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../_static/css/tlcpack_theme.css" type="text/css" />

  
  

  
  
  
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
        <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/_sphinx_javascript_frameworks_compat.js"></script>
        <script src="../_static/doctools.js"></script>
        <script src="../_static/sphinx_highlight.js"></script>
        <script src="../_static/tabs.js"></script>
    
    <script type="text/javascript" src="../_static/js/theme.js"></script>

    
    <script type="text/javascript" src="../_static/js/tlcpack_theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    
<header class="header">
    <div class="innercontainer">
      <div class="headerInner d-flex justify-content-between align-items-center">
          <div class="headerLogo">
          </div>

          <div id="headMenu" class="headerNav">
            <button type="button" id="closeHeadMenu" class="navCloseBtn"><img src="../_static/img/close-icon.svg" alt="Close"></button>
             <ul class="nav">
                <li class="nav-item">
                   <a class="nav-link" href=https://mlc.ai/mlc-llm>Home</a>
                </li>
                <li class="nav-item">
                   <a class="nav-link" href=https://github.com/mlc-ai/mlc-llm>Github</a>
                </li>
                <li class="nav-item">
                   <a class="nav-link" href=https://discord.gg/9Xpy2HGBuD>Discord Server</a>
                </li>
             </ul>
               <div class="responsivetlcdropdown">
                 <button type="button" class="btn-link">
                   Other Resources
                 </button>
                 <ul>
                     <li>
                       <a href=https://mlc.ai/>MLC Course</a>
                     </li>
                     <li>
                       <a href=https://mlc.ai/blog>MLC Blog</a>
                     </li>
                     <li>
                       <a href=https://mlc.ai/web-llm>Web LLM</a>
                     </li>
                 </ul>
               </div>
          </div>
            <div class="responsiveMenuIcon">
              <button type="button" id="menuBtn" class="btn-menu"><img src="../_static/img/menu-icon.svg" alt="Menu Icon"></button>
            </div>

            <div class="tlcDropdown">
              <div class="dropdown">
                <button type="button" class="btn-link dropdown-toggle" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
                  Other Resources
                </button>
                <div class="dropdown-menu dropdown-menu-right">
                  <ul>
                     <li>
                       <a href=https://mlc.ai/>MLC Course</a>
                     </li>
                     <li>
                       <a href=https://mlc.ai/blog>MLC Blog</a>
                     </li>
                     <li>
                       <a href=https://mlc.ai/web-llm>Web LLM</a>
                     </li>
                  </ul>
                </div>
              </div>
          </div>
       </div>
    </div>
 </header>
 
    <nav data-toggle="wy-nav-shift" class="wy-nav-side fixed">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../index.html">
          

          
            
            <img src="../_static/mlc-logo-with-text-landscape.svg" class="logo" alt="Logo"/>
          
          </a>

          
            
            
                <div class="version">
                  0.1.0
                </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption" role="heading"><span class="caption-text">Get Started</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../get_started/try_out.html">Try out MLC Chat</a></li>
<li class="toctree-l1"><a class="reference internal" href="../get_started/project_overview.html">Project Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../get_started/mlc_chat_config.html">Configure MLCChat in JSON</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Build and Deploy Apps</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../deploy/javascript.html">WebLLM and Javascript API</a></li>
<li class="toctree-l1"><a class="reference internal" href="../deploy/rest.html">Rest API</a></li>
<li class="toctree-l1"><a class="reference internal" href="../deploy/cli.html">CLI and C++ API</a></li>
<li class="toctree-l1"><a class="reference internal" href="../deploy/python.html">Python API and Gradio Frontend</a></li>
<li class="toctree-l1"><a class="reference internal" href="../deploy/ios.html">iOS App and Swift API</a></li>
<li class="toctree-l1"><a class="reference internal" href="../deploy/android.html">Android App</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Compile Models</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="compile_models.html">Compile Models via MLC</a></li>
<li class="toctree-l1"><a class="reference internal" href="distribute_compiled_models.html">Distribute Compiled Models</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Define Model Architectures</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../tutorials/customize/define_new_models.html">üöß Define New Model Architectures</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Prebuilt Models</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../prebuilt_models.html">Model Prebuilts</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Dependency Installation</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../install/tvm.html">Install TVM Unity</a></li>
<li class="toctree-l1"><a class="reference internal" href="../install/conda.html">Install Conda</a></li>
<li class="toctree-l1"><a class="reference internal" href="../install/gpu.html">GPU Drivers and SDKs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../install/emcc.html">Install Wasm Build Environment</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Community</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../community/guideline.html">Community Guideline</a></li>
<li class="toctree-l1"><a class="reference internal" href="../community/faq.html">Frequently Asked Questions</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">
      
      <nav class="wy-nav-top" aria-label="top navigation" data-toggle="wy-nav-top">
        
            <div class="togglemenu">

            </div>
            <div class="nav-content">
              <!-- mlc-llm -->
              Table of Contents
            </div>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        

          




















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../index.html">Docs</a> <span class="br-arrow">></span></li>
        
      <li>How to Compile Models</li>
    
    
      
      
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            
              <a href="https://github.com/mlc-ai/mlc-llm/edit/main/docs/compilation/compile_models_legacy.rst" class="fa fa-github"> Edit on GitHub</a>
            
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <section id="how-to-compile-models">
<span id="id1"></span><h1>How to Compile Models<a class="headerlink" href="#how-to-compile-models" title="Permalink to this heading">¬∂</a></h1>
<p>In this tutorial, we will guide you on how to build an LLM with architectures that are already supported by MLC LLM for different backends. Before proceeding with this tutorial, make sure you have completed the <span class="xref std std-doc">/install/index</span> tutorial. In the following content, we assume that you have already installed the necessary components and will not cover the installation steps.</p>
<p>We have provided a list of off-the-shelf prebuilt models (<a class="reference internal" href="../prebuilt_models.html"><span class="doc">Model Prebuilts</span></a>) that you can directly use without the need for building. To learn how to deploy these models, refer to the tutorial :doc:deploy-models.</p>
<p>If your model is not included in the list of off-the-shelf models, but its architecture falls within the supported model architectures (see the <a class="reference internal" href="../prebuilt_models.html#supported-model-architectures"><span class="std std-ref">Supported Model Architectures</span></a> section), you can follow this tutorial to build your model for different backends.</p>
<p>In the event that your model architecture is not supported, you can refer to the tutorial <span class="xref std std-doc">bring-your-own-models</span> to learn how to introduce new model architectures.</p>
<p>This tutorial contains the following sections in order:</p>
<nav class="contents local" id="table-of-contents">
<p class="topic-title">Table of Contents</p>
<ul class="simple">
<li><p><a class="reference internal" href="#dependencies" id="id2">Dependencies</a></p></li>
<li><p><a class="reference internal" href="#prepare-model-weight" id="id3">Prepare Model Weight</a></p></li>
<li><p><a class="reference internal" href="#run-build-script" id="id4">Run Build Script</a></p></li>
<li><p><a class="reference internal" href="#why-need-build" id="id5">Why Need Build?</a></p></li>
<li><p><a class="reference internal" href="#troubleshooting-faq" id="id6">Troubleshooting FAQ</a></p></li>
</ul>
</nav>
<section id="dependencies">
<span id="compile-model-dependencies"></span><h2><a class="toc-backref" href="#id2" role="doc-backlink">Dependencies</a><a class="headerlink" href="#dependencies" title="Permalink to this heading">¬∂</a></h2>
<p><a class="reference internal" href="../install/tvm.html"><span class="doc">TVM-Unity</span></a> is required to compile models.</p>
</section>
<section id="prepare-model-weight">
<span id="compile-model-prepare-model-weight"></span><h2><a class="toc-backref" href="#id3" role="doc-backlink">Prepare Model Weight</a><a class="headerlink" href="#prepare-model-weight" title="Permalink to this heading">¬∂</a></h2>
<p>This section briefly introduces how to prepare the weight of the model we want to build.</p>
<section id="models-with-full-weight">
<span id="compile-models-with-full-weight"></span><h3>Models with Full Weight<a class="headerlink" href="#models-with-full-weight" title="Permalink to this heading">¬∂</a></h3>
<p>For models whose full weight is directly available (e.g., <a class="reference external" href="https://huggingface.co/togethercomputer/RedPajama-INCITE-Chat-3B-v1">RedPajama-v1-3B on Hugging Face</a>), we need to put the model to path <code class="docutils literal notranslate"><span class="pre">dist/models/MODEL_NAME</span></code> under the path of your MLC LLM.</p>
<ul>
<li><p>If the model weight is hosted on <a class="reference external" href="https://huggingface.co">Hugging Face</a>, we can download the model via git clone. For example, the commands below download the RedPajama-v1-3B weight to <code class="docutils literal notranslate"><span class="pre">dist/models/RedPajama-INCITE-Chat-3B-v1</span></code>.</p>
<blockquote>
<div><div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>git<span class="w"> </span>lfs<span class="w"> </span>install
git<span class="w"> </span>clone<span class="w"> </span>https://huggingface.co/togethercomputer/RedPajama-INCITE-Chat-3B-v1<span class="w"> </span>dist/models/RedPajama-INCITE-Chat-3B-v1
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Depending on the model size and the Hugging Face repository, the git clone operation might take a while (for example, cloning the RedPajama-v1-3B model takes about 10 min on one of our dev workstation).</p>
</div>
</div></blockquote>
</li>
<li><p>If you have your own fine-tuned model, directly copy your model to <code class="docutils literal notranslate"><span class="pre">dist/models/MODEL_NAME</span></code>.</p>
<blockquote>
<div><div class="admonition note">
<p class="admonition-title">Note</p>
<p>An alternative approach (which saves disk space) is to use symbolic link to link your model to <code class="docutils literal notranslate"><span class="pre">dist/models/MODEL_NAME</span></code>:</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>ln<span class="w"> </span>-s<span class="w"> </span>path/to/your/model<span class="w"> </span>dist/models/MODEL_NAME
</pre></div>
</div>
</div>
</div></blockquote>
</li>
</ul>
</section>
<section id="models-with-base-weight-and-delta-weight">
<span id="compile-models-with-base-weight-and-delta-weight"></span><h3>Models with Base Weight and Delta Weight<a class="headerlink" href="#models-with-base-weight-and-delta-weight" title="Permalink to this heading">¬∂</a></h3>
<p>For models whose base weight and delta weight are available (e.g., Vicuna-v1-7B only releases the <a class="reference external" href="https://huggingface.co/lmsys/vicuna-7b-delta-v1.1">delta weight</a> on Hugging Face), we need to apply the delta weights to the base weight. You can refer to the instructions of <a class="reference external" href="https://github.com/lm-sys/FastChat#vicuna-weights">getting Vicuna model weight</a> as a reference. After getting the full weight of the model, copy or symbolic link the model to <code class="docutils literal notranslate"><span class="pre">dist/models/MODEL_NAME</span></code>.</p>
</section>
</section>
<section id="run-build-script">
<span id="compile-models-run-build-script"></span><h2><a class="toc-backref" href="#id4" role="doc-backlink">Run Build Script</a><a class="headerlink" href="#run-build-script" title="Permalink to this heading">¬∂</a></h2>
<p>To run the build script ‚Äúbuild.py‚Äù in the MLC LLM path, follow the command pattern below:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>python3<span class="w"> </span>build.py<span class="w"> </span>--model<span class="w"> </span>MODEL_NAME_OR_PATH<span class="w"> </span>--target<span class="w"> </span>TARGET_NAME<span class="w"> </span>--quantization<span class="w"> </span>QUANTIZATION_NAME<span class="w"> </span><span class="o">[</span>--hf-path<span class="w"> </span>HUGGINGFACE_PATH<span class="o">]</span><span class="w"> </span><span class="o">[</span>--artifact-path<span class="w"> </span>ARTIFACT_PATH<span class="o">]</span><span class="w"> </span><span class="o">[</span>--db-path<span class="w"> </span>DB_PATH<span class="o">]</span><span class="w"> </span><span class="o">[</span>--max-seq-len<span class="w"> </span>MAX_ALLOWED_SEQUENCE_LENGTH<span class="o">]</span><span class="w"> </span><span class="o">[</span>--use-cache<span class="o">=</span><span class="m">0</span><span class="o">]</span><span class="w"> </span><span class="o">[</span>--reuse-lib<span class="o">]</span>
</pre></div>
</div>
<p>The necessary arguments for the build script are listed in the table below:</p>
<dl class="option-list">
<dt><kbd><span class="option">--model</span></kbd></dt>
<dd><p>The name of the model to build. The default value is <code class="docutils literal notranslate"><span class="pre">auto</span></code>. If set to <code class="docutils literal notranslate"><span class="pre">auto</span></code>, the model name will be
automatically determined based on <code class="docutils literal notranslate"><span class="pre">--hf-path</span></code>. Otherwise, the model name will be searched in the artifact folder.</p>
</dd>
<dt><kbd><span class="option">--hf-path</span></kbd></dt>
<dd><p>(optional): Hugging Face path from which to download parameters, tokenizer, and configuration (e.g.,
<code class="docutils literal notranslate"><span class="pre">stabilityai/stablelm-base-alpha-7b</span></code>). The default value is <code class="docutils literal notranslate"><span class="pre">None</span></code>, indicating that the model will not be downloaded
from Hugging Face, but rather use the local model specified by <code class="docutils literal notranslate"><span class="pre">--model</span></code>.</p>
</dd>
<dt><kbd><span class="option">--target</span></kbd></dt>
<dd><p>The target device to build the model for. The default value is <code class="docutils literal notranslate"><span class="pre">auto</span></code>, which allows the script to automatically detect
the target device. Available options are: <code class="docutils literal notranslate"><span class="pre">auto</span></code>, <code class="docutils literal notranslate"><span class="pre">metal</span></code> (for M1/M2), <code class="docutils literal notranslate"><span class="pre">metal_x86_64</span></code> (for Intel CPU), <code class="docutils literal notranslate"><span class="pre">iphone</span></code>,
<code class="docutils literal notranslate"><span class="pre">vulkan</span></code>, <code class="docutils literal notranslate"><span class="pre">cuda</span></code>, <code class="docutils literal notranslate"><span class="pre">webgpu</span></code>, <code class="docutils literal notranslate"><span class="pre">android</span></code>, and <code class="docutils literal notranslate"><span class="pre">opencl</span></code>.</p>
</dd>
<dt><kbd><span class="option">--quantization</span></kbd></dt>
<dd><p>The code indicating the quantization mode to use. The format of the code is <code class="docutils literal notranslate"><span class="pre">qAfB(_0)</span></code>, where <code class="docutils literal notranslate"><span class="pre">A</span></code> represents the number
of bits for storing weights and <code class="docutils literal notranslate"><span class="pre">B</span></code> represents the number of bits for storing activations. The <code class="docutils literal notranslate"><span class="pre">_0</span></code> suffix indicates
symmetric quantization is used (if not presented, asymmetric quantization is used). Available options are: <code class="docutils literal notranslate"><span class="pre">q3f16_0</span></code>, <code class="docutils literal notranslate"><span class="pre">q4f16_0</span></code>,
<code class="docutils literal notranslate"><span class="pre">q4f32_0</span></code>, <code class="docutils literal notranslate"><span class="pre">q0f32</span></code>, <code class="docutils literal notranslate"><span class="pre">q0f16</span></code>, and <code class="docutils literal notranslate"><span class="pre">q8f16_0</span></code>. The default value is <code class="docutils literal notranslate"><span class="pre">q3f16_0</span></code>.</p>
</dd>
</dl>
<p>The following arguments are optional:</p>
<dl class="option-list">
<dt><kbd><span class="option">--artifact-path</span></kbd></dt>
<dd><p>The path to the artifact folder where models are stored. The default value is <code class="docutils literal notranslate"><span class="pre">dist</span></code>.</p>
</dd>
<dt><kbd><span class="option">--db-path</span></kbd></dt>
<dd><p>The path to the database folder where TVM auto-tuning results are stored. The default value is <code class="docutils literal notranslate"><span class="pre">log_db</span></code>.</p>
</dd>
<dt><kbd><span class="option">--max-seq-len</span></kbd></dt>
<dd><p>The maximum allowed sequence length for the model. The default value is <code class="docutils literal notranslate"><span class="pre">-1</span></code>, indicating no limit on the sequence length.</p>
</dd>
<dt><kbd><span class="option">--use-cache</span></kbd></dt>
<dd><p>Specifies whether to use previously pickled IRModule and skip tracing. The default value is <code class="docutils literal notranslate"><span class="pre">1</span></code>, enabling cache reuse.
To disable caching and build the model from scratch, set <code class="docutils literal notranslate"><span class="pre">--use-cache=0</span></code>.</p>
</dd>
<dt><kbd><span class="option">--reuse-lib</span></kbd></dt>
<dd><p>Specifies whether to reuse a previously generated library. This is useful when building the same model architecture with different weights.</p>
</dd>
</dl>
<section id="model-building-examples">
<span id="compile-models-build-examples"></span><h3>Model Building Examples<a class="headerlink" href="#model-building-examples" title="Permalink to this heading">¬∂</a></h3>
<div class="sphinx-tabs docutils container">
<div aria-label="Tabbed content" class="closeable" role="tablist"><button aria-controls="panel-0-0-0" aria-selected="true" class="sphinx-tabs-tab" id="tab-0-0-0" name="0-0" role="tab" tabindex="0">Model: vicuna-v1-7b</button><button aria-controls="panel-0-0-1" aria-selected="false" class="sphinx-tabs-tab" id="tab-0-0-1" name="0-1" role="tab" tabindex="-1">RedPajama-v1-3B</button><button aria-controls="panel-0-0-2" aria-selected="false" class="sphinx-tabs-tab" id="tab-0-0-2" name="0-2" role="tab" tabindex="-1">rwkv-raven-1b5/3b/7b</button><button aria-controls="panel-0-0-3" aria-selected="false" class="sphinx-tabs-tab" id="tab-0-0-3" name="0-3" role="tab" tabindex="-1">Other models</button></div><div aria-labelledby="tab-0-0-0" class="sphinx-tabs-panel" id="panel-0-0-0" name="0-0" role="tabpanel" tabindex="0"><div class="sphinx-tabs docutils container">
<div aria-label="Tabbed content" class="closeable" role="tablist"><button aria-controls="panel-1-1-0" aria-selected="true" class="sphinx-tabs-tab" id="tab-1-1-0" name="1-0" role="tab" tabindex="0">Target: CUDA</button><button aria-controls="panel-1-1-1" aria-selected="false" class="sphinx-tabs-tab" id="tab-1-1-1" name="1-1" role="tab" tabindex="-1">Metal</button><button aria-controls="panel-1-1-2" aria-selected="false" class="sphinx-tabs-tab" id="tab-1-1-2" name="1-2" role="tab" tabindex="-1">Vulkan</button><button aria-controls="panel-1-1-3" aria-selected="false" class="sphinx-tabs-tab" id="tab-1-1-3" name="1-3" role="tab" tabindex="-1">WebGPU</button><button aria-controls="panel-1-1-4" aria-selected="false" class="sphinx-tabs-tab" id="tab-1-1-4" name="1-4" role="tab" tabindex="-1">iPhone/iPad</button><button aria-controls="panel-1-1-5" aria-selected="false" class="sphinx-tabs-tab" id="tab-1-1-5" name="1-5" role="tab" tabindex="-1">Android</button></div><div aria-labelledby="tab-1-1-0" class="sphinx-tabs-panel" id="panel-1-1-0" name="1-0" role="tabpanel" tabindex="0"><div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>python3<span class="w"> </span>build.py<span class="w"> </span>--model<span class="w"> </span>vicuna-v1-7b<span class="w"> </span>--target<span class="w"> </span>cuda<span class="w"> </span>--quantization<span class="w"> </span>q3f16_0
</pre></div>
</div>
</div><div aria-labelledby="tab-1-1-1" class="sphinx-tabs-panel" hidden="true" id="panel-1-1-1" name="1-1" role="tabpanel" tabindex="0"><p>On Apple Silicon powered Mac, build for Apple Silicon Mac:</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>python3<span class="w"> </span>build.py<span class="w"> </span>--model<span class="w"> </span>vicuna-v1-7b<span class="w"> </span>--target<span class="w"> </span>metal<span class="w"> </span>--quantization<span class="w"> </span>q3f16_0
</pre></div>
</div>
<p>On Apple Silicon powered Mac, build for x86 Mac:</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>python3<span class="w"> </span>build.py<span class="w"> </span>--model<span class="w"> </span>vicuna-v1-7b<span class="w"> </span>--target<span class="w"> </span>metal_x86_64<span class="w"> </span>--quantization<span class="w"> </span>q3f16_0
</pre></div>
</div>
</div><div aria-labelledby="tab-1-1-2" class="sphinx-tabs-panel" hidden="true" id="panel-1-1-2" name="1-2" role="tabpanel" tabindex="0"><p>On Linux, build for Linux:</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>python3<span class="w"> </span>build.py<span class="w"> </span>--model<span class="w"> </span>vicuna-v1-7b<span class="w"> </span>--target<span class="w"> </span>vulkan<span class="w"> </span>--quantization<span class="w"> </span>q3f16_0
</pre></div>
</div>
<p>On Linux, build for Windows:</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>python3<span class="w"> </span>build.py<span class="w"> </span>--model<span class="w"> </span>vicuna-v1-7b<span class="w"> </span>--target<span class="w"> </span>vulkan<span class="w"> </span>--quantization<span class="w"> </span>q3f16_0<span class="w"> </span>--llvm-mingw<span class="w"> </span>path/to/llvm-mingw
</pre></div>
</div>
</div><div aria-labelledby="tab-1-1-3" class="sphinx-tabs-panel" hidden="true" id="panel-1-1-3" name="1-3" role="tabpanel" tabindex="0"><div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>python3<span class="w"> </span>build.py<span class="w"> </span>--model<span class="w"> </span>vicuna-v1-7b<span class="w"> </span>--target<span class="w"> </span>llvm<span class="w"> </span>--quantization<span class="w"> </span>q4f32_0
</pre></div>
</div>
</div><div aria-labelledby="tab-1-1-4" class="sphinx-tabs-panel" hidden="true" id="panel-1-1-4" name="1-4" role="tabpanel" tabindex="0"><div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>python3<span class="w"> </span>build.py<span class="w"> </span>--model<span class="w"> </span>vicuna-v1-7b<span class="w"> </span>--target<span class="w"> </span>iphone<span class="w"> </span>--max-seq-len<span class="w"> </span><span class="m">768</span><span class="w"> </span>--quantization<span class="w"> </span>q3f16_0
</pre></div>
</div>
</div><div aria-labelledby="tab-1-1-5" class="sphinx-tabs-panel" hidden="true" id="panel-1-1-5" name="1-5" role="tabpanel" tabindex="0"><div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>python3<span class="w"> </span>build.py<span class="w"> </span>--model<span class="w"> </span>vicuna-v1-7b<span class="w"> </span>--target<span class="w"> </span>android<span class="w"> </span>--max-seq-len<span class="w"> </span><span class="m">768</span><span class="w"> </span>--quantization<span class="w"> </span>q4f16_0
</pre></div>
</div>
</div></div>
</div><div aria-labelledby="tab-0-0-1" class="sphinx-tabs-panel" hidden="true" id="panel-0-0-1" name="0-1" role="tabpanel" tabindex="0"><div class="sphinx-tabs docutils container">
<div aria-label="Tabbed content" class="closeable" role="tablist"><button aria-controls="panel-2-2-0" aria-selected="true" class="sphinx-tabs-tab" id="tab-2-2-0" name="2-0" role="tab" tabindex="0">Target: CUDA</button><button aria-controls="panel-2-2-1" aria-selected="false" class="sphinx-tabs-tab" id="tab-2-2-1" name="2-1" role="tab" tabindex="-1">Metal</button><button aria-controls="panel-2-2-2" aria-selected="false" class="sphinx-tabs-tab" id="tab-2-2-2" name="2-2" role="tab" tabindex="-1">Vulkan</button><button aria-controls="panel-2-2-3" aria-selected="false" class="sphinx-tabs-tab" id="tab-2-2-3" name="2-3" role="tab" tabindex="-1">WebGPU</button><button aria-controls="panel-2-2-4" aria-selected="false" class="sphinx-tabs-tab" id="tab-2-2-4" name="2-4" role="tab" tabindex="-1">iPhone/iPad</button><button aria-controls="panel-2-2-5" aria-selected="false" class="sphinx-tabs-tab" id="tab-2-2-5" name="2-5" role="tab" tabindex="-1">Android</button></div><div aria-labelledby="tab-2-2-0" class="sphinx-tabs-panel" id="panel-2-2-0" name="2-0" role="tabpanel" tabindex="0"><div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>python3<span class="w"> </span>build.py<span class="w"> </span>--model<span class="w"> </span>RedPajama-INCITE-Chat-3B-v1<span class="w"> </span>--target<span class="w"> </span>cuda<span class="w"> </span>--quantization<span class="w"> </span>q3f16_0
</pre></div>
</div>
</div><div aria-labelledby="tab-2-2-1" class="sphinx-tabs-panel" hidden="true" id="panel-2-2-1" name="2-1" role="tabpanel" tabindex="0"><p>On Apple Silicon powered Mac, build for Apple Silicon Mac:</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>python3<span class="w"> </span>build.py<span class="w"> </span>--model<span class="w"> </span>RedPajama-INCITE-Chat-3B-v1<span class="w"> </span>--target<span class="w"> </span>metal<span class="w"> </span>--quantization<span class="w"> </span>q3f16_0
</pre></div>
</div>
<p>On Apple Silicon powered Mac, build for x86 Mac:</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>python3<span class="w"> </span>build.py<span class="w"> </span>--model<span class="w"> </span>RedPajama-INCITE-Chat-3B-v1<span class="w"> </span>--target<span class="w"> </span>metal_x86_64<span class="w"> </span>--quantization<span class="w"> </span>q3f16_0
</pre></div>
</div>
</div><div aria-labelledby="tab-2-2-2" class="sphinx-tabs-panel" hidden="true" id="panel-2-2-2" name="2-2" role="tabpanel" tabindex="0"><p>On Linux, build for Linux:</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>python3<span class="w"> </span>build.py<span class="w"> </span>--model<span class="w"> </span>RedPajama-INCITE-Chat-3B-v1<span class="w"> </span>--target<span class="w"> </span>vulkan<span class="w"> </span>--quantization<span class="w"> </span>q3f16_0
</pre></div>
</div>
<p>On Linux, build for Windows:</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>python3<span class="w"> </span>build.py<span class="w"> </span>--model<span class="w"> </span>RedPajama-INCITE-Chat-3B-v1<span class="w"> </span>--target<span class="w"> </span>vulkan<span class="w"> </span>--quantization<span class="w"> </span>q3f16_0<span class="w"> </span>--llvm-mingw<span class="w"> </span>path/to/llvm-mingw
</pre></div>
</div>
</div><div aria-labelledby="tab-2-2-3" class="sphinx-tabs-panel" hidden="true" id="panel-2-2-3" name="2-3" role="tabpanel" tabindex="0"><div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>python3<span class="w"> </span>build.py<span class="w"> </span>--model<span class="w"> </span>RedPajama-INCITE-Chat-3B-v1<span class="w"> </span>--target<span class="w"> </span>llvm<span class="w"> </span>--quantization<span class="w"> </span>q4f32_0
</pre></div>
</div>
</div><div aria-labelledby="tab-2-2-4" class="sphinx-tabs-panel" hidden="true" id="panel-2-2-4" name="2-4" role="tabpanel" tabindex="0"><div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>python3<span class="w"> </span>build.py<span class="w"> </span>--model<span class="w"> </span>RedPajama-INCITE-Chat-3B-v1<span class="w"> </span>--target<span class="w"> </span>iphone<span class="w"> </span>--max-seq-len<span class="w"> </span><span class="m">768</span><span class="w"> </span>--quantization<span class="w"> </span>q3f16_0
</pre></div>
</div>
</div><div aria-labelledby="tab-2-2-5" class="sphinx-tabs-panel" hidden="true" id="panel-2-2-5" name="2-5" role="tabpanel" tabindex="0"><div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>python3<span class="w"> </span>build.py<span class="w"> </span>--model<span class="w"> </span>RedPajama-INCITE-Chat-3B-v1<span class="w"> </span>--target<span class="w"> </span>android<span class="w"> </span>--max-seq-len<span class="w"> </span><span class="m">768</span><span class="w"> </span>--quantization<span class="w"> </span>q4f16_0
</pre></div>
</div>
</div></div>
</div><div aria-labelledby="tab-0-0-2" class="sphinx-tabs-panel" hidden="true" id="panel-0-0-2" name="0-2" role="tabpanel" tabindex="0"><div class="sphinx-tabs docutils container">
<div aria-label="Tabbed content" class="closeable" role="tablist"><button aria-controls="panel-3-3-0" aria-selected="true" class="sphinx-tabs-tab" id="tab-3-3-0" name="3-0" role="tab" tabindex="0">Target: CUDA</button><button aria-controls="panel-3-3-1" aria-selected="false" class="sphinx-tabs-tab" id="tab-3-3-1" name="3-1" role="tab" tabindex="-1">Metal</button><button aria-controls="panel-3-3-2" aria-selected="false" class="sphinx-tabs-tab" id="tab-3-3-2" name="3-2" role="tab" tabindex="-1">Vulkan</button><button aria-controls="panel-3-3-3" aria-selected="false" class="sphinx-tabs-tab" id="tab-3-3-3" name="3-3" role="tab" tabindex="-1">iPhone/iPad</button></div><div aria-labelledby="tab-3-3-0" class="sphinx-tabs-panel" id="panel-3-3-0" name="3-0" role="tabpanel" tabindex="0"><div class="highlight-shell notranslate"><div class="highlight"><pre><span></span><span class="c1"># For 1.5B model</span>
python3<span class="w"> </span>build.py<span class="w"> </span>--hf-path<span class="o">=</span>RWKV/rwkv-raven-1b5<span class="w"> </span>--target<span class="w"> </span>cuda<span class="w"> </span>--quantization<span class="w"> </span>q8f16_0
<span class="c1"># For 3B model</span>
python3<span class="w"> </span>build.py<span class="w"> </span>--hf-path<span class="o">=</span>RWKV/rwkv-raven-3b<span class="w"> </span>--target<span class="w"> </span>cuda<span class="w"> </span>--quantization<span class="w"> </span>q8f16_0
<span class="c1"># For 7B model</span>
python3<span class="w"> </span>build.py<span class="w"> </span>--hf-path<span class="o">=</span>RWKV/rwkv-raven-7b<span class="w"> </span>--target<span class="w"> </span>cuda<span class="w"> </span>--quantization<span class="w"> </span>q8f16_0
</pre></div>
</div>
</div><div aria-labelledby="tab-3-3-1" class="sphinx-tabs-panel" hidden="true" id="panel-3-3-1" name="3-1" role="tabpanel" tabindex="0"><p>On Apple Silicon powered Mac, build for Apple Silicon Mac:</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span><span class="c1"># For 1.5B model</span>
python3<span class="w"> </span>build.py<span class="w"> </span>--hf-path<span class="o">=</span>RWKV/rwkv-raven-1b5<span class="w"> </span>--target<span class="w"> </span>metal<span class="w"> </span>--quantization<span class="w"> </span>q8f16_0
<span class="c1"># For 3B model</span>
python3<span class="w"> </span>build.py<span class="w"> </span>--hf-path<span class="o">=</span>RWKV/rwkv-raven-3b<span class="w"> </span>--target<span class="w"> </span>metal<span class="w"> </span>--quantization<span class="w"> </span>q8f16_0
<span class="c1"># For 7B model</span>
python3<span class="w"> </span>build.py<span class="w"> </span>--hf-path<span class="o">=</span>RWKV/rwkv-raven-7b<span class="w"> </span>--target<span class="w"> </span>metal<span class="w"> </span>--quantization<span class="w"> </span>q8f16_0
</pre></div>
</div>
<p>On Apple Silicon powered Mac, build for x86 Mac:</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span><span class="c1"># For 1.5B model</span>
python3<span class="w"> </span>build.py<span class="w"> </span>--hf-path<span class="o">=</span>RWKV/rwkv-raven-1b5<span class="w"> </span>--target<span class="w"> </span>metal_x86_64<span class="w"> </span>--quantization<span class="w"> </span>q8f16_0
<span class="c1"># For 3B model</span>
python3<span class="w"> </span>build.py<span class="w"> </span>--hf-path<span class="o">=</span>RWKV/rwkv-raven-3b<span class="w"> </span>--target<span class="w"> </span>metal_x86_64<span class="w"> </span>--quantization<span class="w"> </span>q8f16_0
<span class="c1"># For 7B model</span>
python3<span class="w"> </span>build.py<span class="w"> </span>--hf-path<span class="o">=</span>RWKV/rwkv-raven-7b<span class="w"> </span>--target<span class="w"> </span>metal_x86_64<span class="w"> </span>--quantization<span class="w"> </span>q8f16_0
</pre></div>
</div>
</div><div aria-labelledby="tab-3-3-2" class="sphinx-tabs-panel" hidden="true" id="panel-3-3-2" name="3-2" role="tabpanel" tabindex="0"><p>On Linux, build for Linux:</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span><span class="c1"># For 1.5B model</span>
python3<span class="w"> </span>build.py<span class="w"> </span>--hf-path<span class="o">=</span>RWKV/rwkv-raven-1b5<span class="w"> </span>--target<span class="w"> </span>vulkan<span class="w"> </span>--quantization<span class="w"> </span>q8f16_0
<span class="c1"># For 3B model</span>
python3<span class="w"> </span>build.py<span class="w"> </span>--hf-path<span class="o">=</span>RWKV/rwkv-raven-3b<span class="w"> </span>--target<span class="w"> </span>vulkan<span class="w"> </span>--quantization<span class="w"> </span>q8f16_0
<span class="c1"># For 7B model</span>
python3<span class="w"> </span>build.py<span class="w"> </span>--hf-path<span class="o">=</span>RWKV/rwkv-raven-7b<span class="w"> </span>--target<span class="w"> </span>vulkan<span class="w"> </span>--quantization<span class="w"> </span>q8f16_0
</pre></div>
</div>
<p>On Linux, build for Windows:</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span><span class="c1"># For 1.5B model</span>
python3<span class="w"> </span>build.py<span class="w"> </span>--hf-path<span class="o">=</span>RWKV/rwkv-raven-1b5<span class="w"> </span>--target<span class="w"> </span>vulkan<span class="w"> </span>--quantization<span class="w"> </span>q8f16_0<span class="w"> </span>--llvm-mingw<span class="w"> </span>path/to/llvm-mingw
<span class="c1"># For 3B model</span>
python3<span class="w"> </span>build.py<span class="w"> </span>--hf-path<span class="o">=</span>RWKV/rwkv-raven-3b<span class="w"> </span>--target<span class="w"> </span>vulkan<span class="w"> </span>--quantization<span class="w"> </span>q8f16_0<span class="w"> </span>--llvm-mingw<span class="w"> </span>path/to/llvm-mingw
<span class="c1"># For 7B model</span>
python3<span class="w"> </span>build.py<span class="w"> </span>--hf-path<span class="o">=</span>RWKV/rwkv-raven-7b<span class="w"> </span>--target<span class="w"> </span>vulkan<span class="w"> </span>--quantization<span class="w"> </span>q8f16_0<span class="w"> </span>--llvm-mingw<span class="w"> </span>path/to/llvm-mingw
</pre></div>
</div>
</div><div aria-labelledby="tab-3-3-3" class="sphinx-tabs-panel" hidden="true" id="panel-3-3-3" name="3-3" role="tabpanel" tabindex="0"><div class="highlight-shell notranslate"><div class="highlight"><pre><span></span><span class="c1"># For 1.5B model</span>
python3<span class="w"> </span>build.py<span class="w"> </span>--hf-path<span class="o">=</span>RWKV/rwkv-raven-1b5<span class="w"> </span>--target<span class="w"> </span>iphone<span class="w"> </span>--quantization<span class="w"> </span>q8f16_0
<span class="c1"># For 3B model</span>
python3<span class="w"> </span>build.py<span class="w"> </span>--hf-path<span class="o">=</span>RWKV/rwkv-raven-3b<span class="w"> </span>--target<span class="w"> </span>iphone<span class="w"> </span>--quantization<span class="w"> </span>q8f16_0
<span class="c1"># For 7B model</span>
python3<span class="w"> </span>build.py<span class="w"> </span>--hf-path<span class="o">=</span>RWKV/rwkv-raven-7b<span class="w"> </span>--target<span class="w"> </span>iphone<span class="w"> </span>--quantization<span class="w"> </span>q8f16_0
</pre></div>
</div>
</div></div>
</div><div aria-labelledby="tab-0-0-3" class="sphinx-tabs-panel" hidden="true" id="panel-0-0-3" name="0-3" role="tabpanel" tabindex="0"><div class="sphinx-tabs docutils container">
<div aria-label="Tabbed content" class="closeable" role="tablist"><button aria-controls="panel-4-4-0" aria-selected="true" class="sphinx-tabs-tab" id="tab-4-4-0" name="4-0" role="tab" tabindex="0">Target: CUDA</button><button aria-controls="panel-4-4-1" aria-selected="false" class="sphinx-tabs-tab" id="tab-4-4-1" name="4-1" role="tab" tabindex="-1">Metal</button><button aria-controls="panel-4-4-2" aria-selected="false" class="sphinx-tabs-tab" id="tab-4-4-2" name="4-2" role="tab" tabindex="-1">Vulkan</button><button aria-controls="panel-4-4-3" aria-selected="false" class="sphinx-tabs-tab" id="tab-4-4-3" name="4-3" role="tab" tabindex="-1">WebGPU</button><button aria-controls="panel-4-4-4" aria-selected="false" class="sphinx-tabs-tab" id="tab-4-4-4" name="4-4" role="tab" tabindex="-1">iPhone/iPad</button><button aria-controls="panel-4-4-5" aria-selected="false" class="sphinx-tabs-tab" id="tab-4-4-5" name="4-5" role="tab" tabindex="-1">Android</button></div><div aria-labelledby="tab-4-4-0" class="sphinx-tabs-panel" id="panel-4-4-0" name="4-0" role="tabpanel" tabindex="0"><div class="highlight-shell notranslate"><div class="highlight"><pre><span></span><span class="c1"># Download and put the model to `dist/models/MODEL_NAME`, and then run</span>
python3<span class="w"> </span>build.py<span class="w"> </span>--model<span class="w"> </span>MODEL_NAME<span class="w"> </span>--target<span class="w"> </span>cuda<span class="w"> </span>--quantization<span class="w"> </span>q3f16_0
</pre></div>
</div>
</div><div aria-labelledby="tab-4-4-1" class="sphinx-tabs-panel" hidden="true" id="panel-4-4-1" name="4-1" role="tabpanel" tabindex="0"><p>On Apple Silicon powered Mac, build for Apple Silicon Mac:</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span><span class="c1"># Download and put the model to `dist/models/MODEL_NAME`, and then run</span>
python3<span class="w"> </span>build.py<span class="w"> </span>--model<span class="w"> </span>MODEL_NAME<span class="w"> </span>--target<span class="w"> </span>metal<span class="w"> </span>--quantization<span class="w"> </span>q3f16_0
</pre></div>
</div>
<p>On Apple Silicon powered Mac, build for x86 Mac:</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span><span class="c1"># Download and put the model to `dist/models/MODEL_NAME`, and then run</span>
python3<span class="w"> </span>build.py<span class="w"> </span>--model<span class="w"> </span>MODEL_NAME<span class="w"> </span>--target<span class="w"> </span>metal_x86_64<span class="w"> </span>--quantization<span class="w"> </span>q3f16_0
</pre></div>
</div>
</div><div aria-labelledby="tab-4-4-2" class="sphinx-tabs-panel" hidden="true" id="panel-4-4-2" name="4-2" role="tabpanel" tabindex="0"><p>On Linux, build for Linux:</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span><span class="c1"># Download and put the model to `dist/models/MODEL_NAME`, and then run</span>
python3<span class="w"> </span>build.py<span class="w"> </span>--model<span class="w"> </span>MODEL_NAME<span class="w"> </span>--target<span class="w"> </span>vulkan<span class="w"> </span>--quantization<span class="w"> </span>q3f16_0
</pre></div>
</div>
<p>On Linux, build for Windows:</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span><span class="c1"># Download and put the model to `dist/models/MODEL_NAME`, and then run</span>
python3<span class="w"> </span>build.py<span class="w"> </span>--model<span class="w"> </span>MODEL_NAME<span class="w"> </span>--target<span class="w"> </span>vulkan<span class="w"> </span>--quantization<span class="w"> </span>q3f16_0<span class="w"> </span>--llvm-mingw<span class="w"> </span>path/to/llvm-mingw
</pre></div>
</div>
</div><div aria-labelledby="tab-4-4-3" class="sphinx-tabs-panel" hidden="true" id="panel-4-4-3" name="4-3" role="tabpanel" tabindex="0"><div class="highlight-shell notranslate"><div class="highlight"><pre><span></span><span class="c1"># Download and put the model to `dist/models/MODEL_NAME`, and then run</span>
python3<span class="w"> </span>build.py<span class="w"> </span>--model<span class="w"> </span>MODEL_NAME<span class="w"> </span>--target<span class="w"> </span>llvm<span class="w"> </span>--quantization<span class="w"> </span>q4f32_0
</pre></div>
</div>
</div><div aria-labelledby="tab-4-4-4" class="sphinx-tabs-panel" hidden="true" id="panel-4-4-4" name="4-4" role="tabpanel" tabindex="0"><div class="highlight-shell notranslate"><div class="highlight"><pre><span></span><span class="c1"># Download and put the model to `dist/models/MODEL_NAME`, and then run</span>
python3<span class="w"> </span>build.py<span class="w"> </span>--model<span class="w"> </span>MODEL_NAME<span class="w"> </span>--target<span class="w"> </span>iphone<span class="w"> </span>--max-seq-len<span class="w"> </span><span class="m">768</span><span class="w"> </span>--quantization<span class="w"> </span>q3f16_0
</pre></div>
</div>
</div><div aria-labelledby="tab-4-4-5" class="sphinx-tabs-panel" hidden="true" id="panel-4-4-5" name="4-5" role="tabpanel" tabindex="0"><div class="highlight-shell notranslate"><div class="highlight"><pre><span></span><span class="c1"># Download and put the model to `dist/models/MODEL_NAME`, and then run</span>
python3<span class="w"> </span>build.py<span class="w"> </span>--model<span class="w"> </span>MODEL_NAME<span class="w"> </span>--target<span class="w"> </span>android<span class="w"> </span>--max-seq-len<span class="w"> </span><span class="m">768</span><span class="w"> </span>--quantization<span class="w"> </span>q4f16_0
</pre></div>
</div>
</div></div>
</div></div>
<p>Here are some notes on the build commands above:</p>
<ul class="simple">
<li><p>For each model and each backend, we only provide the most recommended build command (which is the most optimized). You can also try with different argument values (e.g., different quantization modes), whose build results do not run as fast and robustly as the provided one in deployment.</p></li>
<li><p>After a successful build, the build script outputs some cache files for quicker future builds. If you want to ignore the cached files and want to build from the very beginning, please append <code class="docutils literal notranslate"><span class="pre">--use-cache=0</span></code> to the end of the build command.</p></li>
<li><p>You can add <code class="docutils literal notranslate"><span class="pre">--debug-dump</span></code> to the build command to  optionally specifies if we will write some dump files for debugging.</p></li>
</ul>
<p>After running the build script successfully, you deploy the model by following tutorial <span class="xref std std-doc">/tutorials/deploy-models</span>.</p>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>In certain cases, using 3-bit quantization for compiling can be overly aggressive and may result in the compiled model generating meaningless text. If you encounter issues where the compiled model does not perform as expected, consider utilizing a higher number of bits for quantization (e.g., 4-bit quantization).</p>
</div>
</section>
</section>
<section id="why-need-build">
<span id="compile-models-why-need-build"></span><h2><a class="toc-backref" href="#id5" role="doc-backlink">Why Need Build?</a><a class="headerlink" href="#why-need-build" title="Permalink to this heading">¬∂</a></h2>
<p>As supplementary, this section explains what the <strong>build</strong> means in MLC LLM. Compared with PyTorch that runs every model in <em>eager mode</em>, the overall workflow of MLC LLM separates model execution into two major stages: <strong>build</strong> and <strong>deployment</strong>.
This separation enables us to build LLM to different backends using a single common flow and also supports us to optimize the LLM execution towards better runtime performance (less run time).</p>
<ul class="simple">
<li><p>In the build stage, MLC LLM takes the model, the target backend, and other configurable arguments as input, applies optimizations and transformations that accelerate the execution of the model on the target backend, and generates a set of output for the deployment stage. The set of output includes a binary library file for the model specific to the target backend, the quantized model weights, the tokenizer files specific to the model, and a config JSON file that contains some model basic information as well as the configurable parameters for deployment (such as the chat temperature). The output (and only the output) generated by the build stage will be consumed by the deployment stage.</p></li>
<li><p>The deployment stage runs on the target backend (e.g., web browser, mobile phones, etc.). It takes the output of the build stage as input and provides an interface for people to interact with the model we build. The interface can be a command line if the model is deployed to the native desktop/laptop environment or a chat box if the model is deployed to web browser and mobile phones.</p></li>
</ul>
<img alt="compilation workflow" class="align-center" src="https://mlc.ai/blog/img/redpajama/customization.svg" /></section>
<section id="troubleshooting-faq">
<span id="compile-models-troubleshooting"></span><h2><a class="toc-backref" href="#id6" role="doc-backlink">Troubleshooting FAQ</a><a class="headerlink" href="#troubleshooting-faq" title="Permalink to this heading">¬∂</a></h2>
<p>(draft)</p>
<details class="summary-q-i-encountered-the-unable-to-parse-tuningrecord-error-immediately-when-i-run-the-build-script">
<summary>Q: I encountered the ``Unable to parse TuningRecord`` error immediately when I run the build script.</summary><p>Please update your MLC LLM codebase to the latest by git.</p>
</details><details class="summary-q-i-encountered-error-when-building-the-moss-model">
<summary>Q: I encountered error when building the Moss model.</summary><p>Moss support is still ongoing and we are now working on it. Please try other models first.</p>
</details><ul class="simple">
<li><p>LLVM error (<a class="reference external" href="https://github.com/mlc-ai/mlc-llm/issues/182">https://github.com/mlc-ai/mlc-llm/issues/182</a>)</p></li>
<li><p>Windows unresolved external symbols (<a class="reference external" href="https://github.com/mlc-ai/mlc-llm/issues/194">https://github.com/mlc-ai/mlc-llm/issues/194</a>)</p></li>
</ul>
</section>
</section>


           </div>
           
          </div>
          

<footer>

<div id="button" class="backtop"><img src="../_static/img/right.svg" alt="backtop"/> </div>
<section class="footerSec">
    <div class="footerHeader">
      <div class="d-flex align-md-items-center justify-content-between flex-column flex-md-row">
        <div class="copywrite d-flex align-items-center">
          <h5 id="copy-right-info">¬© 2023 MLC LLM</h5>
        </div>
      </div>

    </div>

    <div>
      <div class="footernote"> </div>
    </div>

</section>
</footer>
        </div>
      </div>

    </section>

  </div>
  

    <script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.12.9/umd/popper.min.js" integrity="sha384-ApNbgh9B+Y1QKtv3Rn7W3mgPxhU9K/ScQsAP7hUibX39j7fakFPskvXusvfa0b4Q" crossorigin="anonymous"></script>
    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0/js/bootstrap.min.js" integrity="sha384-JZR6Spejh4U02d8jOt6vLEHfe/JQGiRRSQQxSfFWpi1MquVdAyjUar5+76PVCmYl" crossorigin="anonymous"></script>

  </body>
  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>