





<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8">
  <meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Install TVM Unity Compiler &mdash; mlc-llm 0.1.0 documentation</title>
  

  
  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0/css/bootstrap.min.css" integrity="sha384-Gn5384xqQ1aoWXA+058RXPxPg6fy4IWvTNh0E263XmFcJlSAwiGgFAW/dAiS6JXm" crossorigin="anonymous">
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/tabs.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../_static/css/tlcpack_theme.css" type="text/css" />

  
  

  
  
  
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
        <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/_sphinx_javascript_frameworks_compat.js"></script>
        <script src="../_static/doctools.js"></script>
        <script src="../_static/sphinx_highlight.js"></script>
        <script src="../_static/tabs.js"></script>
    
    <script type="text/javascript" src="../_static/js/theme.js"></script>

    
    <script type="text/javascript" src="../_static/js/tlcpack_theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Install MLC LLM Python Package" href="mlc_llm.html" />
    <link rel="prev" title="Define New Model Architectures" href="../compilation/define_new_models.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    
<header class="header">
    <div class="innercontainer">
      <div class="headerInner d-flex justify-content-between align-items-center">
          <div class="headerLogo">
          </div>

          <div id="headMenu" class="headerNav">
            <button type="button" id="closeHeadMenu" class="navCloseBtn"><img src="../_static/img/close-icon.svg" alt="Close"></button>
             <ul class="nav">
                <li class="nav-item">
                   <a class="nav-link" href=https://llm.mlc.ai/>Home</a>
                </li>
                <li class="nav-item">
                   <a class="nav-link" href=https://github.com/mlc-ai/mlc-llm>Github</a>
                </li>
                <li class="nav-item">
                   <a class="nav-link" href=https://discord.gg/9Xpy2HGBuD>Discord Server</a>
                </li>
             </ul>
               <div class="responsivetlcdropdown">
                 <button type="button" class="btn-link">
                   Other Resources
                 </button>
                 <ul>
                     <li>
                       <a href=https://mlc.ai/>MLC Course</a>
                     </li>
                     <li>
                       <a href=https://blog.mlc.ai/>MLC Blog</a>
                     </li>
                     <li>
                       <a href=https://webllm.mlc.ai/>Web LLM</a>
                     </li>
                 </ul>
               </div>
          </div>
            <div class="responsiveMenuIcon">
              <button type="button" id="menuBtn" class="btn-menu"><img src="../_static/img/menu-icon.svg" alt="Menu Icon"></button>
            </div>

            <div class="tlcDropdown">
              <div class="dropdown">
                <button type="button" class="btn-link dropdown-toggle" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
                  Other Resources
                </button>
                <div class="dropdown-menu dropdown-menu-right">
                  <ul>
                     <li>
                       <a href=https://mlc.ai/>MLC Course</a>
                     </li>
                     <li>
                       <a href=https://blog.mlc.ai/>MLC Blog</a>
                     </li>
                     <li>
                       <a href=https://webllm.mlc.ai/>Web LLM</a>
                     </li>
                  </ul>
                </div>
              </div>
          </div>
       </div>
    </div>
 </header>
 
    <nav data-toggle="wy-nav-shift" class="wy-nav-side fixed">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../index.html">
          

          
            
            <img src="../_static/mlc-logo-with-text-landscape.svg" class="logo" alt="Logo"/>
          
          </a>

          
            
            
                <div class="version">
                  0.1.0
                </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption" role="heading"><span class="caption-text">Get Started</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../get_started/quick_start.html">Quick Start</a></li>
<li class="toctree-l1"><a class="reference internal" href="../get_started/introduction.html">Introduction to MLC LLM</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Build and Deploy Apps</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../deploy/webllm.html">WebLLM Javascript SDK</a></li>
<li class="toctree-l1"><a class="reference internal" href="../deploy/rest.html">REST API</a></li>
<li class="toctree-l1"><a class="reference internal" href="../deploy/cli.html">CLI</a></li>
<li class="toctree-l1"><a class="reference internal" href="../deploy/python_engine.html">Python API</a></li>
<li class="toctree-l1"><a class="reference internal" href="../deploy/ios.html">iOS Swift SDK</a></li>
<li class="toctree-l1"><a class="reference internal" href="../deploy/android.html">Android SDK</a></li>
<li class="toctree-l1"><a class="reference internal" href="../deploy/ide_integration.html">IDE Integration</a></li>
<li class="toctree-l1"><a class="reference internal" href="../deploy/mlc_chat_config.html">Customize MLC Chat Config</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Compile Models</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../compilation/convert_weights.html">Convert Model Weights</a></li>
<li class="toctree-l1"><a class="reference internal" href="../compilation/compile_models.html">Compile Model Libraries</a></li>
<li class="toctree-l1"><a class="reference internal" href="../compilation/package_libraries_and_weights.html">Package Libraries and Weights</a></li>
<li class="toctree-l1"><a class="reference internal" href="../compilation/define_new_models.html">Define New Model Architectures</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Dependency Installation</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="current reference internal" href="#">Install TVM Unity Compiler</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#option-1-prebuilt-package">Option 1. Prebuilt Package</a></li>
<li class="toctree-l2"><a class="reference internal" href="#option-2-build-from-source">Option 2. Build from Source</a></li>
<li class="toctree-l2"><a class="reference internal" href="#validate-tvm-installation">Validate TVM Installation</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="mlc_llm.html">Install MLC LLM Python Package</a></li>
<li class="toctree-l1"><a class="reference internal" href="conda.html">Install Conda</a></li>
<li class="toctree-l1"><a class="reference internal" href="gpu.html">GPU Drivers and SDKs</a></li>
<li class="toctree-l1"><a class="reference internal" href="emcc.html">Install Wasm Build Environment</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Community</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../community/guideline.html">Community Guideline</a></li>
<li class="toctree-l1"><a class="reference internal" href="../community/faq.html">Frequently Asked Questions</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Privacy</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../privacy.html">MLC Chat App Privacy</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">
      
      <nav class="wy-nav-top" aria-label="top navigation" data-toggle="wy-nav-top">
        
            <div class="togglemenu">

            </div>
            <div class="nav-content">
              <!-- mlc-llm -->
              Table of Contents
            </div>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        

          




















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../index.html">Docs</a> <span class="br-arrow">></span></li>
        
      <li>Install TVM Unity Compiler</li>
    
    
      
      
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            
              <a href="https://github.com/mlc-ai/mlc-llm/edit/main/docs/install/tvm.rst" class="fa fa-github"> Edit on GitHub</a>
            
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <section id="install-tvm-unity-compiler">
<span id="install-tvm-unity"></span><h1>Install TVM Unity Compiler<a class="headerlink" href="#install-tvm-unity-compiler" title="Permalink to this heading">¶</a></h1>
<nav class="contents local" id="table-of-contents">
<p class="topic-title">Table of Contents</p>
<ul class="simple">
<li><p><a class="reference internal" href="#option-1-prebuilt-package" id="id5">Option 1. Prebuilt Package</a></p></li>
<li><p><a class="reference internal" href="#option-2-build-from-source" id="id6">Option 2. Build from Source</a></p></li>
<li><p><a class="reference internal" href="#validate-tvm-installation" id="id7">Validate TVM Installation</a></p></li>
</ul>
</nav>
<p><a class="reference external" href="https://discuss.tvm.apache.org/t/establish-tvm-unity-connection-a-technical-strategy/13344">TVM Unity</a>, the latest development in Apache TVM, is required to build MLC LLM. Its features include:</p>
<ul class="simple">
<li><p>High-performance CPU/GPU code generation instantly without tuning;</p></li>
<li><p>Dynamic shape and symbolic shape tracking by design;</p></li>
<li><p>Supporting both inference and training;</p></li>
<li><p>Productive python-first compiler implementation. As a concrete example, MLC LLM compilation is implemented in pure python using its API.</p></li>
</ul>
<p>TVM Unity can be installed directly from a prebuilt developer package, or built from source.</p>
<section id="option-1-prebuilt-package">
<span id="tvm-unity-prebuilt-package"></span><h2><a class="toc-backref" href="#id5" role="doc-backlink">Option 1. Prebuilt Package</a><a class="headerlink" href="#option-1-prebuilt-package" title="Permalink to this heading">¶</a></h2>
<p>A nightly prebuilt Python package of Apache TVM Unity is provided.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>❗ Whenever using Python, it is highly recommended to use <strong>conda</strong> to manage an isolated Python environment to avoid missing dependencies, incompatible versions, and package conflicts.</p>
</div>
<div class="sphinx-tabs docutils container">
<div aria-label="Tabbed content" class="closeable" role="tablist"><button aria-controls="panel-0-0-0" aria-selected="true" class="sphinx-tabs-tab" id="tab-0-0-0" name="0-0" role="tab" tabindex="0">Linux</button><button aria-controls="panel-0-0-1" aria-selected="false" class="sphinx-tabs-tab" id="tab-0-0-1" name="0-1" role="tab" tabindex="-1">macOS</button><button aria-controls="panel-0-0-2" aria-selected="false" class="sphinx-tabs-tab" id="tab-0-0-2" name="0-2" role="tab" tabindex="-1">Windows</button></div><div aria-labelledby="tab-0-0-0" class="sphinx-tabs-panel" id="panel-0-0-0" name="0-0" role="tabpanel" tabindex="0"><div class="sphinx-tabs docutils container">
<div aria-label="Tabbed content" class="closeable" role="tablist"><button aria-controls="panel-1-1-0" aria-selected="true" class="sphinx-tabs-tab" id="tab-1-1-0" name="1-0" role="tab" tabindex="0">CPU</button><button aria-controls="panel-1-1-1" aria-selected="false" class="sphinx-tabs-tab" id="tab-1-1-1" name="1-1" role="tab" tabindex="-1">CUDA 12.1</button><button aria-controls="panel-1-1-2" aria-selected="false" class="sphinx-tabs-tab" id="tab-1-1-2" name="1-2" role="tab" tabindex="-1">CUDA 12.2</button><button aria-controls="panel-1-1-3" aria-selected="false" class="sphinx-tabs-tab" id="tab-1-1-3" name="1-3" role="tab" tabindex="-1">ROCm 6.1</button><button aria-controls="panel-1-1-4" aria-selected="false" class="sphinx-tabs-tab" id="tab-1-1-4" name="1-4" role="tab" tabindex="-1">ROCm 6.2</button><button aria-controls="panel-1-1-5" aria-selected="false" class="sphinx-tabs-tab" id="tab-1-1-5" name="1-5" role="tab" tabindex="-1">Vulkan</button></div><div aria-labelledby="tab-1-1-0" class="sphinx-tabs-panel" id="panel-1-1-0" name="1-0" role="tabpanel" tabindex="0"><div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>conda<span class="w"> </span>activate<span class="w"> </span>your-environment
python<span class="w"> </span>-m<span class="w"> </span>pip<span class="w"> </span>install<span class="w"> </span>--pre<span class="w"> </span>-U<span class="w"> </span>-f<span class="w"> </span>https://mlc.ai/wheels<span class="w"> </span>mlc-ai-nightly
</pre></div>
</div>
</div><div aria-labelledby="tab-1-1-1" class="sphinx-tabs-panel" hidden="true" id="panel-1-1-1" name="1-1" role="tabpanel" tabindex="0"><div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>conda<span class="w"> </span>activate<span class="w"> </span>your-environment
python<span class="w"> </span>-m<span class="w"> </span>pip<span class="w"> </span>install<span class="w"> </span>--pre<span class="w"> </span>-U<span class="w"> </span>-f<span class="w"> </span>https://mlc.ai/wheels<span class="w"> </span>mlc-ai-nightly-cu121
</pre></div>
</div>
</div><div aria-labelledby="tab-1-1-2" class="sphinx-tabs-panel" hidden="true" id="panel-1-1-2" name="1-2" role="tabpanel" tabindex="0"><div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>conda<span class="w"> </span>activate<span class="w"> </span>your-environment
python<span class="w"> </span>-m<span class="w"> </span>pip<span class="w"> </span>install<span class="w"> </span>--pre<span class="w"> </span>-U<span class="w"> </span>-f<span class="w"> </span>https://mlc.ai/wheels<span class="w"> </span>mlc-ai-nightly-cu122
</pre></div>
</div>
</div><div aria-labelledby="tab-1-1-3" class="sphinx-tabs-panel" hidden="true" id="panel-1-1-3" name="1-3" role="tabpanel" tabindex="0"><div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>conda<span class="w"> </span>activate<span class="w"> </span>your-environment
python<span class="w"> </span>-m<span class="w"> </span>pip<span class="w"> </span>install<span class="w"> </span>--pre<span class="w"> </span>-U<span class="w"> </span>-f<span class="w"> </span>https://mlc.ai/wheels<span class="w"> </span>mlc-ai-nightly-rocm61
</pre></div>
</div>
</div><div aria-labelledby="tab-1-1-4" class="sphinx-tabs-panel" hidden="true" id="panel-1-1-4" name="1-4" role="tabpanel" tabindex="0"><div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>conda<span class="w"> </span>activate<span class="w"> </span>your-environment
python<span class="w"> </span>-m<span class="w"> </span>pip<span class="w"> </span>install<span class="w"> </span>--pre<span class="w"> </span>-U<span class="w"> </span>-f<span class="w"> </span>https://mlc.ai/wheels<span class="w"> </span>mlc-ai-nightly-rocm62
</pre></div>
</div>
</div><div aria-labelledby="tab-1-1-5" class="sphinx-tabs-panel" hidden="true" id="panel-1-1-5" name="1-5" role="tabpanel" tabindex="0"><p>Supported in all Linux packages.</p>
</div></div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>If encountering issues with GLIBC not found, please install the latest glibc in conda:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>conda<span class="w"> </span>install<span class="w"> </span>-c<span class="w"> </span>conda-forge<span class="w"> </span>libgcc-ng
</pre></div>
</div>
</div>
</div><div aria-labelledby="tab-0-0-1" class="sphinx-tabs-panel" hidden="true" id="panel-0-0-1" name="0-1" role="tabpanel" tabindex="0"><div class="sphinx-tabs docutils container">
<div aria-label="Tabbed content" class="closeable" role="tablist"><button aria-controls="panel-2-2-0" aria-selected="true" class="sphinx-tabs-tab" id="tab-2-2-0" name="2-0" role="tab" tabindex="0">CPU + Metal</button></div><blockquote>
<div><div aria-labelledby="tab-2-2-0" class="sphinx-tabs-panel" id="panel-2-2-0" name="2-0" role="tabpanel" tabindex="0"><div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>conda<span class="w"> </span>activate<span class="w"> </span>your-environment
python<span class="w"> </span>-m<span class="w"> </span>pip<span class="w"> </span>install<span class="w"> </span>--pre<span class="w"> </span>-U<span class="w"> </span>-f<span class="w"> </span>https://mlc.ai/wheels<span class="w"> </span>mlc-ai-nightly
</pre></div>
</div>
</div></div></blockquote>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Always check if conda is installed properly in macOS using the command below:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>conda<span class="w"> </span>info<span class="w"> </span><span class="p">|</span><span class="w"> </span>grep<span class="w"> </span>platform
</pre></div>
</div>
<p>It should return “osx-64” for Mac with Intel chip, and “osx-arm64” for Mac with Apple chip.</p>
</div>
</div>
</div><div aria-labelledby="tab-0-0-2" class="sphinx-tabs-panel" hidden="true" id="panel-0-0-2" name="0-2" role="tabpanel" tabindex="0"><div class="sphinx-tabs docutils container">
<div aria-label="Tabbed content" class="closeable" role="tablist"><button aria-controls="panel-3-3-0" aria-selected="true" class="sphinx-tabs-tab" id="tab-3-3-0" name="3-0" role="tab" tabindex="0">CPU + Vulkan</button></div><div aria-labelledby="tab-3-3-0" class="sphinx-tabs-panel" id="panel-3-3-0" name="3-0" role="tabpanel" tabindex="0"><div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>conda<span class="w"> </span>activate<span class="w"> </span>your-environment
python<span class="w"> </span>-m<span class="w"> </span>pip<span class="w"> </span>install<span class="w"> </span>--pre<span class="w"> </span>-U<span class="w"> </span>-f<span class="w"> </span>https://mlc.ai/wheels<span class="w"> </span>mlc-ai-nightly
</pre></div>
</div>
</div></div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Make sure you also install vulkan loader and clang to avoid vulkan
not found error or clang not found(needed for jit compile)</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>conda<span class="w"> </span>install<span class="w"> </span>-c<span class="w"> </span>conda-forge<span class="w"> </span>clang<span class="w"> </span>libvulkan-loader
</pre></div>
</div>
<p>If encountering the error below:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>FileNotFoundError:<span class="w"> </span>Could<span class="w"> </span>not<span class="w"> </span>find<span class="w"> </span>module<span class="w"> </span><span class="s1">&#39;path\to\site-packages\tvm\tvm.dll&#39;</span><span class="w"> </span><span class="o">(</span>or<span class="w"> </span>one<span class="w"> </span>of<span class="w"> </span>its<span class="w"> </span>dependencies<span class="o">)</span>.<span class="w"> </span>Try<span class="w"> </span>using<span class="w"> </span>the<span class="w"> </span>full<span class="w"> </span>path<span class="w"> </span>with<span class="w"> </span>constructor<span class="w"> </span>syntax.
</pre></div>
</div>
<p>It is likely <cite>zstd</cite>, a dependency to LLVM, was missing. Please use the command below to get it installed:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>conda<span class="w"> </span>install<span class="w"> </span>zstd
</pre></div>
</div>
</div>
</div></div>
</section>
<section id="option-2-build-from-source">
<span id="tvm-unity-build-from-source"></span><h2><a class="toc-backref" href="#id6" role="doc-backlink">Option 2. Build from Source</a><a class="headerlink" href="#option-2-build-from-source" title="Permalink to this heading">¶</a></h2>
<p>While it is generally recommended to always use the prebuilt TVM Unity, if you require more customization, you may need to build it from source. <strong>NOTE.</strong> this should only be attempted if you are familiar with the intricacies of C++, CMake, LLVM, Python, and other related systems.</p>
<details class="summary-details">
<summary>Details</summary><p><strong>Step 1. Set up build dependency.</strong> To build from source, you need to ensure that the following build dependencies are met:</p>
<ul class="simple">
<li><p>CMake &gt;= 3.24</p></li>
<li><p>LLVM &gt;= 15
- For please install LLVM&gt;=17 for ROCm 6.1 and LLVM&gt;=18 for ROCm 6.2.</p></li>
<li><p>Git</p></li>
<li><p>(Optional) CUDA &gt;= 11.8 (targeting NVIDIA GPUs)</p></li>
<li><p>(Optional) Metal (targeting Apple GPUs such as M1 and M2)</p></li>
<li><p>(Optional) Vulkan (targeting NVIDIA, AMD, Intel and mobile GPUs)</p></li>
<li><p>(Optional) OpenCL (targeting NVIDIA, AMD, Intel and mobile GPUs)</p></li>
</ul>
<div class="admonition note">
<p class="admonition-title">Note</p>
<ul class="simple">
<li><p>To target NVIDIA GPUs, either CUDA or Vulkan is required (CUDA is recommended);</p></li>
<li><p>For AMD and Intel GPUs, Vulkan is necessary;</p></li>
<li><p>When targeting Apple (macOS, iOS, iPadOS), Metal is a mandatory dependency;</p></li>
<li><p>Some Android devices only support OpenCL, but most of them support Vulkan.</p></li>
</ul>
</div>
<p>To easiest way to manage dependency is via conda, which maintains a set of toolchains including LLVM across platforms. To create the environment of those build dependencies, one may simply use:</p>
<div class="literal-block-wrapper docutils container" id="id1">
<div class="code-block-caption"><span class="caption-text">Set up build dependencies in conda</span><a class="headerlink" href="#id1" title="Permalink to this code">¶</a></div>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="c1"># make sure to start with a fresh environment</span>
conda<span class="w"> </span>env<span class="w"> </span>remove<span class="w"> </span>-n<span class="w"> </span>tvm-build-venv
<span class="c1"># create the conda environment with build dependency</span>
conda<span class="w"> </span>create<span class="w"> </span>-n<span class="w"> </span>tvm-build-venv<span class="w"> </span>-c<span class="w"> </span>conda-forge<span class="w"> </span><span class="se">\</span>
<span class="w">    </span><span class="s2">&quot;llvmdev&gt;=15&quot;</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span><span class="s2">&quot;cmake&gt;=3.24&quot;</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>git<span class="w"> </span><span class="se">\</span>
<span class="w">    </span><span class="nv">python</span><span class="o">=</span><span class="m">3</span>.11
<span class="c1"># enter the build environment</span>
conda<span class="w"> </span>activate<span class="w"> </span>tvm-build-venv
</pre></div>
</div>
</div>
<p><strong>Step 2. Configure and build.</strong> Standard git-based workflow are recommended to download Apache TVM Unity, and then specify build requirements in <code class="docutils literal notranslate"><span class="pre">config.cmake</span></code>:</p>
<div class="literal-block-wrapper docutils container" id="id2">
<div class="code-block-caption"><span class="caption-text">Download TVM Unity from GitHub</span><a class="headerlink" href="#id2" title="Permalink to this code">¶</a></div>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="c1"># clone from GitHub</span>
git<span class="w"> </span>clone<span class="w"> </span>--recursive<span class="w"> </span>https://github.com/mlc-ai/relax.git<span class="w"> </span>tvm-unity<span class="w"> </span><span class="o">&amp;&amp;</span><span class="w"> </span><span class="nb">cd</span><span class="w"> </span>tvm-unity
<span class="c1"># create the build directory</span>
rm<span class="w"> </span>-rf<span class="w"> </span>build<span class="w"> </span><span class="o">&amp;&amp;</span><span class="w"> </span>mkdir<span class="w"> </span>build<span class="w"> </span><span class="o">&amp;&amp;</span><span class="w"> </span><span class="nb">cd</span><span class="w"> </span>build
<span class="c1"># specify build requirements in `config.cmake`</span>
cp<span class="w"> </span>../cmake/config.cmake<span class="w"> </span>.
</pre></div>
</div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>We are temporarily using <a class="reference external" href="https://github.com/mlc-ai/relax">mlc-ai/relax</a> instead, which comes with several temporary outstanding changes that we will upstream to Apache TVM’s <a class="reference external" href="https://github.com/apache/tvm/tree/unity">unity branch</a>.</p>
</div>
<p>We want to specifically tweak the following flags by appending them to the end of the configuration file:</p>
<div class="literal-block-wrapper docutils container" id="id3">
<div class="code-block-caption"><span class="caption-text">Configure build in <code class="docutils literal notranslate"><span class="pre">config.cmake</span></code></span><a class="headerlink" href="#id3" title="Permalink to this code">¶</a></div>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="c1"># controls default compilation flags</span>
<span class="nb">echo</span><span class="w"> </span><span class="s2">&quot;set(CMAKE_BUILD_TYPE RelWithDebInfo)&quot;</span><span class="w"> </span>&gt;&gt;<span class="w"> </span>config.cmake
<span class="c1"># LLVM is a must dependency</span>
<span class="nb">echo</span><span class="w"> </span><span class="s2">&quot;set(USE_LLVM \&quot;llvm-config --ignore-libllvm --link-static\&quot;)&quot;</span><span class="w"> </span>&gt;&gt;<span class="w"> </span>config.cmake
<span class="nb">echo</span><span class="w"> </span><span class="s2">&quot;set(HIDE_PRIVATE_SYMBOLS ON)&quot;</span><span class="w"> </span>&gt;&gt;<span class="w"> </span>config.cmake
<span class="c1"># GPU SDKs, turn on if needed</span>
<span class="nb">echo</span><span class="w"> </span><span class="s2">&quot;set(USE_CUDA   OFF)&quot;</span><span class="w"> </span>&gt;&gt;<span class="w"> </span>config.cmake
<span class="nb">echo</span><span class="w"> </span><span class="s2">&quot;set(USE_METAL  OFF)&quot;</span><span class="w"> </span>&gt;&gt;<span class="w"> </span>config.cmake
<span class="nb">echo</span><span class="w"> </span><span class="s2">&quot;set(USE_VULKAN OFF)&quot;</span><span class="w"> </span>&gt;&gt;<span class="w"> </span>config.cmake
<span class="nb">echo</span><span class="w"> </span><span class="s2">&quot;set(USE_OPENCL OFF)&quot;</span><span class="w"> </span>&gt;&gt;<span class="w"> </span>config.cmake
<span class="c1"># FlashInfer related, requires CUDA w/ compute capability 80;86;89;90</span>
<span class="nb">echo</span><span class="w"> </span><span class="s2">&quot;set(USE_FLASHINFER OFF)&quot;</span><span class="w"> </span>&gt;&gt;<span class="w"> </span>config.cmake
<span class="nb">echo</span><span class="w"> </span><span class="s2">&quot;set(FLASHINFER_CUDA_ARCHITECTURES YOUR_CUDA_COMPUTE_CAPABILITY_HERE)&quot;</span><span class="w"> </span>&gt;&gt;<span class="w"> </span>config.cmake
<span class="nb">echo</span><span class="w"> </span><span class="s2">&quot;set(CMAKE_CUDA_ARCHITECTURES YOUR_CUDA_COMPUTE_CAPABILITY_HERE)&quot;</span><span class="w"> </span>&gt;&gt;<span class="w"> </span>config.cmake
</pre></div>
</div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p><code class="docutils literal notranslate"><span class="pre">HIDE_PRIVATE_SYMBOLS</span></code> is a configuration option that enables the <code class="docutils literal notranslate"><span class="pre">-fvisibility=hidden</span></code> flag. This flag helps prevent potential symbol conflicts between TVM and PyTorch. These conflicts arise due to the frameworks shipping LLVMs of different versions.</p>
<p><a class="reference external" href="https://cmake.org/cmake/help/latest/variable/CMAKE_BUILD_TYPE.html">CMAKE_BUILD_TYPE</a> controls default compilation flag:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">Debug</span></code> sets <code class="docutils literal notranslate"><span class="pre">-O0</span> <span class="pre">-g</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">RelWithDebInfo</span></code> sets <code class="docutils literal notranslate"><span class="pre">-O2</span> <span class="pre">-g</span> <span class="pre">-DNDEBUG</span></code> (recommended)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">Release</span></code> sets <code class="docutils literal notranslate"><span class="pre">-O3</span> <span class="pre">-DNDEBUG</span></code></p></li>
</ul>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>If you are using CUDA and your compute capability is above 80, then it is require to build with
<code class="docutils literal notranslate"><span class="pre">set(USE_FLASHINFER</span> <span class="pre">ON)</span></code>. Otherwise, you may run into <code class="docutils literal notranslate"><span class="pre">Cannot</span> <span class="pre">find</span> <span class="pre">PackedFunc</span></code> issue during
runtime.</p>
<p>To check your CUDA compute capability, you can use <code class="docutils literal notranslate"><span class="pre">nvidia-smi</span> <span class="pre">--query-gpu=compute_cap</span> <span class="pre">--format=csv</span></code>.</p>
</div>
<p>Once <code class="docutils literal notranslate"><span class="pre">config.cmake</span></code> is edited accordingly, kick off build with the commands below:</p>
<div class="literal-block-wrapper docutils container" id="id4">
<div class="code-block-caption"><span class="caption-text">Build <code class="docutils literal notranslate"><span class="pre">libtvm</span></code> using cmake and cmake</span><a class="headerlink" href="#id4" title="Permalink to this code">¶</a></div>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>cmake<span class="w"> </span>..<span class="w"> </span><span class="o">&amp;&amp;</span><span class="w"> </span>cmake<span class="w"> </span>--build<span class="w"> </span>.<span class="w"> </span>--parallel<span class="w"> </span><span class="k">$(</span>nproc<span class="k">)</span>
</pre></div>
</div>
</div>
<p>A success build should produce <code class="docutils literal notranslate"><span class="pre">libtvm</span></code> and <code class="docutils literal notranslate"><span class="pre">libtvm_runtime</span></code> under <code class="docutils literal notranslate"><span class="pre">/path-tvm-unity/build/</span></code> directory.</p>
<p>Leaving the build environment <code class="docutils literal notranslate"><span class="pre">tvm-build-venv</span></code>, there are two ways to install the successful build into your environment:</p>
<div class="sphinx-tabs docutils container">
<div aria-label="Tabbed content" class="closeable" role="tablist"><button aria-controls="panel-4-SW5zdGFsbCB2aWEgZW52aXJvbm1lbnQgdmFyaWFibGU=" aria-selected="true" class="sphinx-tabs-tab code-tab group-tab" id="tab-4-SW5zdGFsbCB2aWEgZW52aXJvbm1lbnQgdmFyaWFibGU=" name="SW5zdGFsbCB2aWEgZW52aXJvbm1lbnQgdmFyaWFibGU=" role="tab" tabindex="0">Install via environment variable</button><button aria-controls="panel-4-SW5zdGFsbCB2aWEgcGlwIGxvY2FsIHByb2plY3Q=" aria-selected="false" class="sphinx-tabs-tab code-tab group-tab" id="tab-4-SW5zdGFsbCB2aWEgcGlwIGxvY2FsIHByb2plY3Q=" name="SW5zdGFsbCB2aWEgcGlwIGxvY2FsIHByb2plY3Q=" role="tab" tabindex="-1">Install via pip local project</button></div><div aria-labelledby="tab-4-SW5zdGFsbCB2aWEgZW52aXJvbm1lbnQgdmFyaWFibGU=" class="sphinx-tabs-panel code-tab group-tab" id="panel-4-SW5zdGFsbCB2aWEgZW52aXJvbm1lbnQgdmFyaWFibGU=" name="SW5zdGFsbCB2aWEgZW52aXJvbm1lbnQgdmFyaWFibGU=" role="tabpanel" tabindex="0"><div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nb">export</span><span class="w"> </span><span class="nv">PYTHONPATH</span><span class="o">=</span>/path-to-tvm-unity/python:<span class="nv">$PYTHONPATH</span>
</pre></div>
</div>
</div><div aria-labelledby="tab-4-SW5zdGFsbCB2aWEgcGlwIGxvY2FsIHByb2plY3Q=" class="sphinx-tabs-panel code-tab group-tab" hidden="true" id="panel-4-SW5zdGFsbCB2aWEgcGlwIGxvY2FsIHByb2plY3Q=" name="SW5zdGFsbCB2aWEgcGlwIGxvY2FsIHByb2plY3Q=" role="tabpanel" tabindex="0"><div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>conda<span class="w"> </span>activate<span class="w"> </span>your-own-env
conda<span class="w"> </span>install<span class="w"> </span>python<span class="w"> </span><span class="c1"># make sure python is installed</span>
<span class="nb">cd</span><span class="w"> </span>/path-to-tvm-unity/python
pip<span class="w"> </span>install<span class="w"> </span>-e<span class="w"> </span>.
</pre></div>
</div>
</div></div>
</details><div class="line-block">
<div class="line"><br /></div>
</div>
</section>
<section id="validate-tvm-installation">
<span id="tvm-unity-validate"></span><h2><a class="toc-backref" href="#id7" role="doc-backlink">Validate TVM Installation</a><a class="headerlink" href="#validate-tvm-installation" title="Permalink to this heading">¶</a></h2>
<p>Using a compiler infrastructure with multiple language bindings could be error-prone.
Therefore, it is highly recommended to validate TVM Unity installation before use.</p>
<p><strong>Step 1. Locate TVM Python package.</strong> The following command can help confirm that TVM is properly installed as a python package and provide the location of the TVM python package:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>&gt;&gt;&gt;<span class="w"> </span>python<span class="w"> </span>-c<span class="w"> </span><span class="s2">&quot;import tvm; print(tvm.__file__)&quot;</span>
/some-path/lib/python3.11/site-packages/tvm/__init__.py
</pre></div>
</div>
<p><strong>Step 2. Confirm which TVM library is used.</strong> When maintaining multiple build or installation of TVM, it becomes important to double check if the python package is using the proper <code class="docutils literal notranslate"><span class="pre">libtvm</span></code> with the following command:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>&gt;&gt;&gt;<span class="w"> </span>python<span class="w"> </span>-c<span class="w"> </span><span class="s2">&quot;import tvm; print(tvm._ffi.base._LIB)&quot;</span>
&lt;CDLL<span class="w"> </span><span class="s1">&#39;/some-path/lib/python3.11/site-packages/tvm/libtvm.dylib&#39;</span>,<span class="w"> </span>handle<span class="w"> </span>95ada510<span class="w"> </span>at<span class="w"> </span>0x1030e4e50&gt;
</pre></div>
</div>
<p><strong>Step 3. Reflect TVM build option.</strong> Sometimes when downstream application fails, it could likely be some mistakes with a wrong TVM commit, or wrong build flags. To find it out, the following commands will be helpful:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>&gt;&gt;&gt;<span class="w"> </span>python<span class="w"> </span>-c<span class="w"> </span><span class="s2">&quot;import tvm; print(&#39;\n&#39;.join(f&#39;{k}: {v}&#39; for k, v in tvm.support.libinfo().items()))&quot;</span>
...<span class="w"> </span><span class="c1"># Omitted less relevant options</span>
GIT_COMMIT_HASH:<span class="w"> </span>4f6289590252a1cf45a4dc37bce55a25043b8338
HIDE_PRIVATE_SYMBOLS:<span class="w"> </span>ON
USE_LLVM:<span class="w"> </span>llvm-config<span class="w"> </span>--link-static
LLVM_VERSION:<span class="w"> </span><span class="m">15</span>.0.7
USE_VULKAN:<span class="w"> </span>OFF
USE_CUDA:<span class="w"> </span>OFF
CUDA_VERSION:<span class="w"> </span>NOT-FOUND
USE_OPENCL:<span class="w"> </span>OFF
USE_METAL:<span class="w"> </span>ON
USE_ROCM:<span class="w"> </span>OFF
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p><code class="docutils literal notranslate"><span class="pre">GIT_COMMIT_HASH</span></code> indicates the exact commit of the TVM build, and it can be found on GitHub via <code class="docutils literal notranslate"><span class="pre">https://github.com/mlc-ai/relax/commit/$GIT_COMMIT_HASH</span></code>.</p>
</div>
<p><strong>Step 4. Check device detection.</strong> Sometimes it could be helpful to understand if TVM could detect your device at all with the following commands:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>&gt;&gt;&gt;<span class="w"> </span>python<span class="w"> </span>-c<span class="w"> </span><span class="s2">&quot;import tvm; print(tvm.metal().exist)&quot;</span>
True<span class="w"> </span><span class="c1"># or False</span>
&gt;&gt;&gt;<span class="w"> </span>python<span class="w"> </span>-c<span class="w"> </span><span class="s2">&quot;import tvm; print(tvm.cuda().exist)&quot;</span>
False<span class="w"> </span><span class="c1"># or True</span>
&gt;&gt;&gt;<span class="w"> </span>python<span class="w"> </span>-c<span class="w"> </span><span class="s2">&quot;import tvm; print(tvm.vulkan().exist)&quot;</span>
False<span class="w"> </span><span class="c1"># or True</span>
</pre></div>
</div>
<p>Please note that the commands above verify the presence of an actual device on the local machine for the TVM runtime (not the compiler) to execute properly. However, TVM compiler can perform compilation tasks without requiring a physical device. As long as the necessary toolchain, such as NVCC, is available, TVM supports cross-compilation even in the absence of an actual device.</p>
</section>
</section>


           </div>
           
          </div>
          

<footer>

    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="mlc_llm.html" class="btn btn-neutral float-right" title="Install MLC LLM Python Package" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="../compilation/define_new_models.html" class="btn btn-neutral float-left" title="Define New Model Architectures" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>

<div id="button" class="backtop"><img src="../_static/img/right.svg" alt="backtop"/> </div>
<section class="footerSec">
    <div class="footerHeader">
      <div class="d-flex align-md-items-center justify-content-between flex-column flex-md-row">
        <div class="copywrite d-flex align-items-center">
          <h5 id="copy-right-info">© 2023 MLC LLM</h5>
        </div>
      </div>

    </div>

    <div>
      <div class="footernote"> </div>
    </div>

</section>
</footer>
        </div>
      </div>

    </section>

  </div>
  

    <script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.12.9/umd/popper.min.js" integrity="sha384-ApNbgh9B+Y1QKtv3Rn7W3mgPxhU9K/ScQsAP7hUibX39j7fakFPskvXusvfa0b4Q" crossorigin="anonymous"></script>
    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0/js/bootstrap.min.js" integrity="sha384-JZR6Spejh4U02d8jOt6vLEHfe/JQGiRRSQQxSfFWpi1MquVdAyjUar5+76PVCmYl" crossorigin="anonymous"></script>

  </body>
  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>